{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "- Load csv into three separate pytorch \"DataLoader\"s, train, validation, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_ = pd.read_csv('./oracle_data.csv')\n",
    "\n",
    "# Pick out data only where object pose changed\n",
    "changed_inds = (dataset_['y_0'] != dataset_['y\\'_0']) | (dataset_['y_1'] != dataset_['y\\'_1']) | (dataset_['y_2'] != dataset_['y\\'_2'])\n",
    "dataset_ = dataset_[changed_inds]\n",
    "dataset = dataset_.copy()\n",
    "\n",
    "# Ignore robot successor state\n",
    "dataset = dataset[[c for c in dataset.columns if 'x\\'' not in c]]\n",
    "\n",
    "# robot relative position\n",
    "object_pos = dataset[[c for c in dataset.columns if 'y_' in c]]\n",
    "for i in range(2):\n",
    "    dataset.loc[:, 'x_{}'.format(i)] -= dataset['y_{}'.format(i)].values\n",
    "# relative object change\n",
    "for i in range(3):\n",
    "    dataset.loc[:, 'y\\'_{}'.format(i)] -= dataset['y_{}'.format(i)].values\n",
    "# drop initial object x, y\n",
    "dataset = dataset[[c for c in dataset.columns if c not in ['y_0', 'y_1']]]\n",
    "\n",
    "# Remake angles θ to cos(θ), sin(θ). Redo as more automatically?\n",
    "angles = dataset['x_2'].copy()\n",
    "dataset['x_2'] = angles.apply('cos')\n",
    "dataset['x_3'] = angles.apply('sin')\n",
    "angles = dataset['y_2'].copy()\n",
    "dataset['y_2'] = angles.apply('cos')\n",
    "dataset['y_3'] = angles.apply('sin')\n",
    "angles = dataset['y\\'_2'].copy()\n",
    "dataset['y\\'_2'] = angles.apply('cos')\n",
    "dataset['y\\'_3'] = angles.apply('sin')\n",
    "\n",
    "dataset = dataset[['x_0', 'x_1', 'x_2', 'x_3', 'y_2', 'y_3', 'y\\'_0', 'y\\'_1', 'y\\'_2', 'y\\'_3',\n",
    "                   'u_0', 'u_1', 'u_2', 'u_3', 'u_4']]\n",
    "\n",
    "# Decide where to split in training/validation/test\n",
    "train_cut = int(len(dataset) * 0.9)\n",
    "valid_cut = train_cut + int(len(dataset) * 0.05)\n",
    "dataset_train_ = dataset[:train_cut]\n",
    "dataset_val_ = dataset[train_cut:valid_cut]\n",
    "dataset_test_ = dataset[valid_cut:]\n",
    "\n",
    "# Normalize by training set statistics\n",
    "training_µ = dataset_train_.mean()\n",
    "training_σ = dataset_train_.std()\n",
    "dataset_train = (dataset_train_ - training_µ) / training_σ\n",
    "dataset_val = (dataset_train_ - training_µ) / training_σ\n",
    "dataset_test = (dataset_train_ - training_µ) / training_σ\n",
    "\n",
    "def get_dataloader(dataset, batch_size=32):\n",
    "    X = dataset[[name for name in dataset.columns if not name.startswith('u')]]\n",
    "    Y = dataset[[name for name in dataset.columns if name.startswith('u')]]\n",
    "    return DataLoader(\n",
    "        list(zip(X.as_matrix().astype(np.float32), Y.as_matrix().astype(np.float32))),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "dataloader_train = get_dataloader(dataset_train)\n",
    "dataloader_val = get_dataloader(dataset_val, batch_size=128)\n",
    "dataloader_test = get_dataloader(dataset_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redo same step to get input/output dimensions\n",
    "X = dataset[[name for name in dataset.columns if not name.startswith('u')]]\n",
    "Y = dataset[[name for name in dataset.columns if name.startswith('u')]]\n",
    "x_size = len(X.columns)\n",
    "y_size = len(Y.columns)\n",
    "x_size, y_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define models\n",
    "- Separate mean and variance models, for stability\n",
    "- MSE loss for the mean, gaussian log likelihood for the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_fn(k):\n",
    "    return int(k * (1 + k) / 2)\n",
    "\n",
    "\n",
    "def k_fn(n):\n",
    "    return int(-0.5 + (0.25 + 2 * n) ** 0.5)\n",
    "\n",
    "\n",
    "hidden_size = 256\n",
    "n_residual_units = 3\n",
    "n_cholesky_entries = n_fn(y_size)\n",
    "\n",
    "\n",
    "class CovarianceCholesky(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(CovarianceCholesky, self).__init__()\n",
    "        self.k = n_features\n",
    "        self.n = int(self.k * (1 + self.k) / 2)\n",
    "        self.row_inds = []\n",
    "        self.col_inds = []\n",
    "        self.diagonal_inds = list(range(self.k))\n",
    "        for i in range(1, self.k):\n",
    "            for j in range(i):\n",
    "                self.row_inds.append(i)\n",
    "                self.col_inds.append(j)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = x.size(1)\n",
    "        k = int(-0.5 + (0.25 + 2 * n) ** 0.5)\n",
    "        y = Variable(torch.zeros(x.size(0), k, k))\n",
    "        if x.data.is_cuda:\n",
    "            y = y.cuda()\n",
    "        y[:, self.row_inds, self.col_inds] = x[:, :n - k]\n",
    "        y[:, self.diagonal_inds, self.diagonal_inds] = F.softplus(x[:, n - k:])\n",
    "        return y\n",
    "\n",
    "class Residual(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features):\n",
    "        super(Residual, self).__init__()\n",
    "        self.bn1 = torch.nn.BatchNorm1d(num_features)\n",
    "        self.fc1 = torch.nn.Linear(num_features, num_features)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(num_features)\n",
    "        self.fc2 = torch.nn.Linear(num_features, num_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a = self.fc1(F.relu(self.bn1(x)))\n",
    "        b = self.fc2(F.relu(self.bn2(a)))\n",
    "        return b + x\n",
    "    \n",
    "\n",
    "mean_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(x_size, hidden_size),\n",
    "    *[Residual(hidden_size) for _ in range(n_residual_units)],\n",
    "    torch.nn.Linear(hidden_size, y_size)\n",
    ").cuda()\n",
    "\n",
    "var_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(x_size, hidden_size),\n",
    "    *[Residual(hidden_size) for _ in range(n_residual_units)],\n",
    "    torch.nn.Linear(hidden_size, y_size),\n",
    "    torch.nn.Softplus()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_likelihood():\n",
    "    def f(µ, σ, y):\n",
    "        return (torch.log(σ) + 0.5 * (µ - y) * (µ - y) / (σ ** 2)).sum()\n",
    "    return f\n",
    "\n",
    "def multivariate_gaussian_likelihood(µ, L, y):\n",
    "    \"\"\"(Average) Negative log-likelihood of a multivariate gaussian.\n",
    "    \n",
    "    Notation below:\n",
    "    n = Number of samples\n",
    "    k = Dimensionality of gaussian variables\n",
    "\n",
    "    µ : Variable, dimensions: (n, k)\n",
    "    L : Lower triangular cholesky decomposition of the covariance matrices, that is LL' = Σ\n",
    "        dimensions: (n, k, k)\n",
    "    y : Variable, dimensions: (n, k)\n",
    "    \"\"\"\n",
    "    n, k = µ.size()\n",
    "    nll = Variable(torch.zeros(1))\n",
    "    if µ.data.is_cuda:\n",
    "        nll = nll.cuda()\n",
    "    for i in range(n):\n",
    "        l = L[i, :, :]\n",
    "        L_inv = torch.inverse(l)\n",
    "        Σ_inv = L_inv.transpose(0, 1) @ L_inv\n",
    "        d = y[i:i + 1, :] - µ[i:i + 1, :]\n",
    "        logdet = 2 * torch.log(l.diag()).sum()\n",
    "        nll += 0.5 * (\n",
    "            logdet +\n",
    "            (d @ Σ_inv @ d.transpose(0, 1)).sum() +\n",
    "            k * np.log(2 * np.pi)\n",
    "        )\n",
    "    return nll / n\n",
    "\n",
    "mean_loss_fn = torch.nn.MSELoss()\n",
    "mean_optim = torch.optim.Adam(mean_model.parameters(), weight_decay=1e-4)\n",
    "var_loss_fn = gaussian_likelihood()\n",
    "var_optim = torch.optim.Adam(var_model.parameters(), weight_decay=1e-4)\n",
    "\n",
    "time_str = datetime.datetime.now().strftime('%H:%M')\n",
    "logger_train = SummaryWriter('runs/resid-6-hidden-256-wd-1e-4-time-{}-relative-train'.format(time_str))\n",
    "logger_valid = SummaryWriter('runs/resid-6-hidden-256-wd-1e-4-time-{}-relative-valid'.format(time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-85c2e416c345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_mean_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mmean_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_mean_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_var_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pytorch/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#best_val = np.inf\n",
    "#best_mean_model = None\n",
    "#best_var_model = None\n",
    "#step = 0\n",
    "for _ in range(1024):\n",
    "    for batch in dataloader_train:\n",
    "        mean_model.train()\n",
    "        var_model.train()\n",
    "        X, Y = map(lambda x: torch.autograd.Variable(x.cuda()), batch)\n",
    "        Y_mean_pred = mean_model(X)\n",
    "        Y_var_pred = var_model(X)\n",
    "\n",
    "        mean_model.zero_grad()\n",
    "        var_model.zero_grad()\n",
    "\n",
    "        mse = mean_loss_fn(Y_mean_pred, Y)\n",
    "        mse.backward(retain_graph=True)\n",
    "        mean_optim.step()\n",
    "\n",
    "        nll = var_loss_fn(Y_mean_pred, Y_var_pred, Y)\n",
    "        nll.backward()\n",
    "        var_optim.step()\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            logger_train.add_scalar('mse', mse.cpu().data.numpy()[0], step)\n",
    "            logger_train.add_scalar('nll', nll.cpu().data.numpy()[0], step)\n",
    "            \n",
    "            mean_model.eval()\n",
    "            var_model.eval()\n",
    "            val_batch = next(iter(dataloader_val))\n",
    "            X, Y = map(lambda x: torch.autograd.Variable(x.cuda()), val_batch)\n",
    "            Y_mean_pred = mean_model(X)\n",
    "            Y_var_pred = var_model(X)\n",
    "\n",
    "            mse_val = mean_loss_fn(Y_mean_pred, Y)\n",
    "            nll_val = var_loss_fn(Y_mean_pred, Y_var_pred, Y).cpu().data.numpy()[0]\n",
    "            \n",
    "            logger_valid.add_scalar('mse', mse_val.cpu().data.numpy()[0], step)\n",
    "            logger_valid.add_scalar('nll', nll_val, step)\n",
    "            \n",
    "            if nll_val < best_val:\n",
    "                best_val = nll_val\n",
    "                best_mean_model = mean_model.state_dict()\n",
    "                best_var_model = var_model.state_dict()\n",
    "\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VOXVwPHfyUZYAoEkRCAIEZAdEVFBFBFQEK2IWsWq\ndavUFrVV31drq7b21YpdwLVad2tdiwu2bqCAKILKvoR9k0AgIRAIhJDtvH/cmziELJNZMjOZ8/18\nxsxd5rknM3LyzLn3Po+oKsYYY5qumFAHYIwxJrgs0RtjTBNnid4YY5o4S/TGGNPEWaI3xpgmzhK9\nMcY0cZboTZ1EREWku/v8GRG5L0DtHi8iB0Uk1l2eKyI/C0Tbbnsfi8i1gWovnIjICBHJ9lheLSIj\nvNnXh2MF7DM3oRMX6gCMQ0S2AulAucfql1X1ltBEdCxVvdmb/dzf5Weq+lkdbX0PtApEXCLyB6C7\nql7t0f75gWg7Eqhq30C0IyLX4XxuZ3q07dVn3lhEZC7wL1V9PtSxRBJL9OHlR3Ulx0oiEqeqZfWt\na2gbjSWUxzYmGlnpJgKIyHUiMl9EpolIPvCHWtbFiMi9IrJNRHJF5J8i0sZto6tbhrlRRL4HZtdy\nrP8VkRwR2SkiN1Tb9rKIPOg+TxWR/4pIgYjsFZEv3eO/ChwP/MctzdxV07E91nl2NrqJyLcickBE\nZohIO/dYx5QfRGSriIwWkbHAb4Er3OMtd7dXlYK8fF+uFZHvRWSPiPyujs+ijfv6PLe9e0UkxuNz\n+kpE/ioi+0Rki4jU+M1CRO4WkenV1j0mIo+7z68XkTUiUigim0Xk53XEtFVERrvPm7uf0z4RyQJO\nrbbvb0Rkk9tulohMcNf3Bp4BhrrvY4G7vuozd5dvEpGN7mf+gYh09NimInKziGxw/794SkSklphP\nE5FF7me9W0SmemwbIiJfu20sF7csJSIPAWcBT7oxPlnbe2KqUVV7hMED2AqMrmXbdUAZcCvOt7Dm\ntay7AdgInIBTFnkXeNVtoyugwD+BlkDzGo4zFtgN9HP3ed19TXd3+8vAg+7zh3ESQ7z7OAuQmn6X\nmo7tsS7O3WcusMPj2O/gfEUHGAFk1/Z+AX+o3Ndj+1ycMgRevi/PuXGdBBwBetfyWfwTmAEkua9d\nD9zo8TmVAjcBscAvgJ2V70u1droARUCSuxwL5ABD3OULgG6AAGe7+w6q6f2o9l5MAb4E2gGdgVXV\n9v0x0BGnk3cFcAjo4BH/V9Xi9PzMRwJ7gEFAM+AJYJ7Hvgr8F0jG+WOfB4yt5X1cAFzjPm/l8Xt3\nAvKBcW6M57rLadU/V3t4/7AefXh53+3FVD5u8ti2U1WfUNUyVT1cy7qrgKmqullVDwL3ABOr9Zr/\noKqHPNrwdDnwkqquUtVDOAm0NqVAB6CLqpaq6pfq/kusQ13HBif5Vh77PuBycU/W+smb9+UBVT2s\nqsuB5TgJ/yhuLBOBe1S1UFW3An8DrvHYbZuqPqeq5cArOO9RevW2VHUbsASY4K4aCRSp6kJ3+4eq\nukkdXwAzcf6Y1udy4CFV3auq24HHqx3336q6U1UrVPUtYANwmhftgvM+vqiqS1T1CM77OFREunrs\nM0VVC9Q5BzMHGFhLW6VAdxFJVdWDlb83cDXwkap+5MY4C1iEk/iNjyzRh5eLVTXZ4/Gcx7btNexf\nfV1HYJvH8jac3r5noqmpHc/Xe27fVtuOwF9weskz3dLCb+rY15tjV9++DeebQqoX7dbHm/dll8fz\nImo+UZzqxlS9rU41taOqRe7T2k46vw5c6T7/ibsMgIicLyIL3RJJAU6i8+a9qPMzFJGfisiyys4E\nzjcob9/jo95H949mPrX8/tT+PgLcCJwIrBWR70TkQnd9F+DHnh0e4EycP5jGR5boI0dNveXq63bi\n/EOpdDxOeWd3Pe1UysH5uu/5+pqDcXq0d6rqCcBFwB0iMqqeY9TX469+7FKcUsEhoEXlBrdnndaA\ndr15X7yxx42pels7GthOpX8DI0QkA6dn/zqAiDTDKV39FUhX1WTgI5wyTn1q/QxFpAtOieoWIMVt\nd5VHuw16H0WkJZCCD7+/qm5Q1SuB9sAjwHS3ve043+w8OzwtVXWKlzGaGliib1reAG4XkUwRaQX8\nCXhLvb/C5W3gOhHpIyItgN/XtqOIXCgi3d2TbftxLgutcDfvxqmHN9TVHsf+IzDdLYGsBxJF5AIR\niQfuxakRV9oNdK08KVoDf98XANxY3gYeEpEkN3HeAfyrIe14tJeHU3N+CdiiqmvcTQk4v18eUOae\n0D3Py2bfBu4RkbbuH5BbPba1xEmUeeCc8MXp0VfaDWSISEItbb8BXC8iA90/Rn8CvnFLWA0iIleL\nSJqqVgAF7uoKnPfyRyIyRkRiRSRRnJPxGR4x+vL/VlSzRB9eKq9UqXy818DXvwi8CswDtgDFHP0P\nvU6q+jHwKM4VORup5cocVw/gM+Agzom1v6vqHHfbw8C97lfv/2lA/K/inPzbBSQCt7lx7Qd+CTyP\n03s8BHhehfNv92e+iCypoV2/3pdqbnWPvxn4CqcX/qKPbeG+fjQeZRtVLcT53d8G9uGUdT7wsr0H\ncMorW3Dq+q96tJuFc05hAU7C7A/M93jtbGA1sEtE9lRvWJ1Lf+/D+baRg3OyeKKXcVU3FlgtIgeB\nx4CJ7jmS7cB4nCup8nB6+P/LD7nqMeAy96qix2to19Sg8ioJY4wxTZT16I0xpomzRG+MMU2cJXpj\njGniLNEbY0wTFxaDmqWmpmrXrl1DHYYxxkSUxYsX71HVtPr2C4tE37VrVxYtWhTqMIwxJqKISF13\nr1ex0o0xxjRxluiNMaaJs0RvjDFNXFjU6I0xTUNpaSnZ2dkUFxeHOpQmJTExkYyMDOLj4316vSV6\nY0zAZGdnk5SURNeuXallcinTQKpKfn4+2dnZZGZm+tRGvaUbEXlRnOnXVtWw7U53+rBUd1lE5HF3\nqrEVIjLIp6iMMRGpuLiYlJQUS/IBJCKkpKT49S3Jmxr9yzgjzVU/eGecoVO/91h9Ps6ohj2AScDT\nPkdmjIlIluQDz9/3tN5Er6rzgL01bJoG3MXREwGMB/7pTn+2EEgWEZsZxhhjQsinq25EZDyww51f\n01Mnjp7GLJujpxnzbGOSOwv8ory8PF/CMCaoVq6EYcPgvYbOCmBMmGlwondn//ktcL8/B1bVZ1V1\nsKoOTkur9w5eYxrd449Dq1bw4IOhjsQY//jSo+8GZALLRWQrkAEsEZHjcGb/8ZyvMgPf59M0JmRK\nSuCdd+C55yA3F9asqf81JjJkZWXRr18/Hn74Yc4++2zKy8sB+OSTT+jZsyfdu3dnypQpdbZxww03\n0L59e/r163fU+pKSEoYPH05ZWYNmqQy6Bid6VV2pqu1VtauqdsUpzwxS1V0405391L36ZgiwX1Vz\nAhuyMcGXlQUdOsDxx8M558CCBaGOyPhi9erVrFix4qh18+bN4z//+Q8VFRVccsklxMbGUl5ezuTJ\nk/n444/JysrijTfeICsrq9Z2r7vuOj755JNj1ickJDBq1CjeeuutgP8u/vDm8so3cOaY7Cki2SJy\nYx27f4Qzl+ZGnNnmfxmQKI1pZMuWwcCBzvOBA51lE3m++OILnn76h4v/iouLadu2LZmZmXz44YeM\nHz8egG+//Zbu3btzwgknkJCQwMSJE5kxY0at7Q4fPpx27drVuO3iiy/mtddeC+wv4qd6b5hS1Svr\n2d7V47kCk/0Py5jQqp7o338/tPFEqq6/+TDgbW6dcoHX++bm5vLee+/x5z//maSkJObOncvo0aMp\nKSlh8+bNVA6PvmPHDjp3/qHqnJGRwTfffONTfP369eO7777z6bXBYnfGGlODZctg3Djn+UknwfLl\noAp2iXjDNCQpB0Pr1q358Y9/zEsvvcRtt91GQUEBKSkp7Ny5k+Tk5KAcMzY2loSEBAoLC0lKSgrK\nMRrKBjUzpgYbNkCvXs7zlBSIj3dOyprIkZWVRe/evbnrrrt44oknOHjwIAkJCQA0b978qDtNO3Xq\nxPbtP1wZnp2dTadONV4Z7pUjR46QmJjoe/ABZonemGqKi2HPHvD8d56ZCVu2hC4m472VK1eydetW\npk+fznnnnUfnzp2ZNGkSEyZMYMiQIQC0bduW8vLyqmR/6qmnsmHDBrZs2UJJSQlvvvkmF110EQCj\nRo1ixw7vLx7Mz88nNTXV5wHIgsESvTHVbNsGnTtDbOwP6yzRR465c+cyYsQIhg8fTqz7Id55552c\ncsopdOzYsWq/8847j6+++gqAuLg4nnzyScaMGUPv3r25/PLL6du3LxUVFWzcuPGYE69XXnklQ4cO\nZd26dWRkZPDCCy9UbZszZw4XXBDaklV1VqM3ppqtW53E7ikz01lvwt+tt97KrbfeetS6mJiYY66N\nnzx5MtOmTWP06NEAjBs3jnGVJ2ZcWVlZXHrppTRv3vyo9W+88Uatx3/99dfrvQ6/sVmP3phqtmyp\nOdFbj75pGTRoEOecc07VDVM16devH1OnTvW6zZKSEi6++GJOPPHEQIQYMJbojalm61Zwr7qr0rWr\nJfqm6IYbbqgq7wRCQkICP/3pTwPWXqBYojemmuxsp0bvqXNnaMD5OGPCiiV6Y6rZudMZ/sBThw7O\nemMikSV6Y6rJyQGPizMAaNvWueyyqCg0MRnjD0v0xlRTU49exFmXY0P0mQhkid4YD4cOOUMU13R3\nvCV6E6ks0RvjISfHSeg1jWnTsaPV6U1kskRvjIfKRF8T69GbSGWJ3hgPluhNsL3//vvcdNNNXHHF\nFcycObNRjmmJ3hgPubnQvn3N29LSnMHOTGQLxFSC3uy7fft2zjnnHPr06UPfvn157LHHAGdikuee\ne45nnnmmaiaqYE9BaIneGA95eU5Cr0lqqiX6SBOMqQS93TcuLo6//e1vZGVlsXDhQp566qmj9nvw\nwQeZPNmZpynYUxBaojfGQ15e7T16S/SRJxhTCXq7b4cOHRg0aBAASUlJ9O7dmx07dqCq3H333Zx/\n/vlV2yG4UxBaojfGg/Xom5bKqQQLCwsBGjSVYG1j0Ddk30pbt25l6dKlnH766TzxxBN89tlnTJ8+\nnWeeeaZqn2BOQWjDFBvjITfXEn0gBWPqRVXv9w3FVILVHTx4kEsvvZRHH32U1q1bc9ttt3Hbbbcd\ns18wpyCst0cvIi+KSK6IrPJY9xcRWSsiK0TkPRFJ9th2j4hsFJF1IjImoNEaE2R19ejbtoWCAqhj\nVFtTjWrgH94K1lSCDdm3tLSUSy+9lKuuuopLLrmk3piDNQWhN6Wbl4Gx1dbNAvqp6gBgPXAPgIj0\nASYCfd3X/F1EAjcGqDFBVleNPi4O2rSBffsaNybTMMGeSrCufT2pKjfeeCO9e/fmjjvuqDfuYE5B\nWG+iV9V5wN5q62aqauV1QAuBDPf5eOBNVT2iqluAjcBpAYzXmKApL3d67Ckpte9j5ZvwF+ypBGvb\nt9K4cePYuXMn8+fP59VXX2X27NkMHDiQgQMH8tFHH9Uad1CnIFTVeh9AV2BVLdv+A1ztPn+y8rm7\n/AJwWX3tn3LKKWpMqOXmqqak1L3P0KGqX37ZOPFEoqysrFCH4LXFixfr1VdfXec+K1eu1Ntvv71R\n4pkwYYKuW7eu1u01vbfAIvUih/t11Y2I/A4oAxp8TZCITBKRRSKyKC8vz58wjAmI/Py6e/Pg9Ojz\n8xsnHhNcwZhK0FfBnoLQ50QvItcBFwJXuX9ZAHYAnnPzZLjrjqGqz6rqYFUdnFbb2S9jGtHeveDx\nDb1GVrppWgI9laCvgj0FoU+JXkTGAncBF6mq51QMHwATRaSZiGQCPYBv/Q/TmODbt88SvWma6r2O\nXkTeAEYAqSKSDfwe5yqbZsAscS6UXaiqN6vqahF5G8jCKelMVlW7GM1EBG979FZpNJGm3kSvqlfW\nsPqFOvZ/CHjIn6CMCQVvE/2aNY0TjzGBYkMgGOOyGr1pqizRG+Pau9e5+7UuluhNJLJEb4zLevSm\nqbJEb4zLEr1pqizRG+PyJtEnJ0NhIZSWNk5MxgSCDVNsjMubRB8T4yT7fftqH/zMeHj3OCjeHbj2\nEtPhkl0+v/zw4cOMHTuW2bNn13qjVElJCaNHj2b27NnExTWNFGk9emNc3iR6+GG4YuOFQCb5ALT3\n4osvVk0fWJtgT+sXCpbojQEqKmD/fqe3Xp/KHr0JXyNGjGDt2rWAM/xvv379AHjttdeqpg8EOOec\nc5g1axYA9957L7feeivg37R+q1at4owzzqhaXrJkCaNGjfKprUBpGt9LjPHT/v3QqpUz5nx92ra1\nRB/uNm7cWDVA2PLly+nfv/8x0wcCPPDAA9x///3k5uaydOlSPvjgA8C/af369OnD5s2bKS8vJzY2\nljvuuKNRBkariyV6Y/C+bANWugl327Zto1OnTsTEOAWLFStWMGDAAPbs2XPM9IHDhw9HVZk6dSpz\n586tKunUNq3f6NGj2bXr2HMEDz30UNU3hZiYGPr27cvq1avZsGEDXbp0OWoS8FCwRG8MTg+9vpul\nKlnpJrwtX76ck046qWp58eLFTJw48ZjpA8GZjSonJ4eUlJRj5mmtaVq/zz77zKsYhgwZwvz58/n7\n3//OJ5984uNvEjhWozcG69E3JcuWLePw4cMAbNiwgQ8++ID+/fsfM31gTk4OV111FTNmzKBVq1ZH\nJWR/p/UbMmQI9957LxMmTKh1PtnGZIneGBqe6K1H76XE9EZvb/ny5ZSXlzNgwAD++Mc/0qdPH155\n5RXgh+kDi4qKuOSSS/jb3/5G7969ue+++3jggQeq2vB3Wr9evXrRrFkz7r77bp/bCCQr3RhDwxJ9\ncjJs3BjceJoMP65599WKFStYsmTJMaUYgMmTJzNt2jRGjx7NggULqtYPHz78qOXXX3+dKVOm+BzD\nY489xsMPP0zLli19biOQrEdvDFa6aSoKCwsRkRqTPHg3faA/0/pt2rSJXr16cfjwYa699toGvz5Y\nrEdvDE6i97aUaqWb8JWUlMT69evr3OeGG26oc7s/0/p169at6vr9cGI9emPwbojiSnbVjYk0luiN\nwSnFeJvorXRjIo0lemNwEnebNt7ta6WbuqlqqENocvx9Ty3RG4P349yA8wfhwAFnfBxztMTERPLz\n8y3ZB5Cqkp+ff8zNWw1hJ2ONwenRe5vo4+KgRQtnXHpvvwVEi4yMDLKzs8nLywt1KE1KYmIiGRkZ\nPr++3kQvIi8CFwK5qtrPXdcOeAvoCmwFLlfVfSIiwGPAOKAIuE5Vl/gcnTGNpCGJHn4o31iiP1p8\nfDyZmZmhDsNU403p5mVgbLV1vwE+V9UewOfuMsD5QA/3MQl4OjBhGhM8FRVOKaZ1a+9fk5xsJ2RN\n5Kg30avqPGBvtdXjgVfc568AF3us/6c6FgLJItIhUMEaEwwHDzqlmIZMJmQnZE0k8fVkbLqq5rjP\ndwGVA1B0ArZ77JftrjuGiEwSkUUissjqeSaUGlq2AbvE0kQWv6+6Uef0eoNPsavqs6o6WFUHp6Wl\n+RuGMT7zJdHbTVMmkvia6HdXlmTcn7nu+h1AZ4/9Mtx1xoQtX3v0luhNpPA10X8AVI7Ycy0ww2P9\nT8UxBNjvUeIxJiw15GapSla6MZGk3kQvIm8AC4CeIpItIjcCU4BzRWQDMNpdBvgI2AxsBJ4DfhmU\nqI0JoIbcLFXJSjcmktR7nYGqXlnLpmOmNXfr9ZP9DcqYxmQnY01TZ0MgmKjn68lYS/QmUliiN1HP\nlxp9mzaW6E3ksERvop6vNXpL9CZSWKI3Uc/X0s3+/cGJx5hAs0Rvop7V6E1TZ4neRD1fEn2rVnD4\nMJSVBScmYwLJEr2Jer6cjBVxXmPlGxMJLNGbqOfLyViw8o2JHJboTVRT9a1HD5boTeSwRG+iWlER\nxMdDs2YNf60lehMpLNGbqOZrbx4s0ZvIYYneRDVf6/Ngid5EDkv0Jqr5cmllJUv0JlJYojdRzRK9\niQaW6E1Us0RvooElehPV9u+3k7Gm6bNEb6Ka9ehNNLBEb6KaP4nexqQ3kcISvYlq1qM30cASvYlq\ndsOUiQaW6E1UsxumTDTwK9GLyO0islpEVonIGyKSKCKZIvKNiGwUkbdEJCFQwRoTaP6Ublq1csbK\nsTHpTbjzOdGLSCfgNmCwqvYDYoGJwCPANFXtDuwDbgxEoMYEgz+JPibGxqQ3kcHf0k0c0FxE4oAW\nQA4wEpjubn8FuNjPYxgTNP7U6MHKNyYy+JzoVXUH8Ffge5wEvx9YDBSoauWX2WygU02vF5FJIrJI\nRBbl5eX5GoYxfikogLZtfX+9JXoTCfwp3bQFxgOZQEegJTDW29er6rOqOlhVB6elpfkahjE+Ky52\nJh5JTPS9jeRkK92Y8OdP6WY0sEVV81S1FHgXGAYku6UcgAxgh58xGhMUlfV5Ed/bsB69iQT+JPrv\ngSEi0kJEBBgFZAFzgMvcfa4FZvgXojHB4c+J2EqW6E0kiKt/l5qp6jciMh1YApQBS4FngQ+BN0Xk\nQXfdC4EI1JhA27evhkT/ukf3/idabxuW6E0k8DnRA6jq74HfV1u9GTjNn3aNaQz+nogFS/QmMtid\nsSZqWenGRAtL9CZqWaI30cISvYlaluhNtLBEb6JWIBK9jUlvIoElehO19u2zk7EmOliiN1HLSjcm\nWliiN1HLEr2JFpboTdQKRKJPSoJDh2xMehPeLNGbqBWIRB8TA61bw4EDgYnJmGCwRG+iViDujAUr\n35jwZ4neRCVV56obfyYdqWSJ3oQ7S/QmKhUVQXw8NGvmf1uW6E24s0RvolIg6vOVLNGbcGeJ3kQl\nS/QmmliiN1EpUCdiwRK9CX+W6E1Ush69iSaW6E1UqnF2KR9ZojfhzhK9iUqB7tHv3x+YtowJBkv0\nJioFMtHbUMUm3FmiN1HJTsaaaGKJ3kQlOxlroolfiV5EkkVkuoisFZE1IjJURNqJyCwR2eD+DFC/\nyZjAsZOxJpr426N/DPhEVXsBJwFrgN8An6tqD+Bzd9mYsOJVj/51+eFRB0v0Jtz5nOhFpA0wHHgB\nQFVLVLUAGA+84u72CnCxv0EaE2iBLN20bg0HD0J5eWDaMybQ/OnRZwJ5wEsislREnheRlkC6qua4\n++wC0mt6sYhMEpFFIrIoLy/PjzCMabhAnoyNiXEmILEx6U248ifRxwGDgKdV9WTgENXKNKqqgNb0\nYlV9VlUHq+rgtLQ0P8IwpuEC2aMHK9+Y8OZPos8GslX1G3d5Ok7i3y0iHQDcn7n+hWhMYKk6NzgF\nYiz6SpboTTjzOdGr6i5gu4j0dFeNArKAD4Br3XXXAjP8itCYACsshObNIS4ucG1aojfhzN//1W8F\nXhORBGAzcD3OH4+3ReRGYBtwuZ/HMCagAl22AUv0Jrz5lehVdRkwuIZNo/xp15hgClai37cvsG0a\nEyh2Z6yJOnv3Qrt2gW2zbVtL9CZ8WaI3USc/H1JSAttmSorTrjHhyBK9iTrB6NG3a+e0a0w4skRv\noo716E20sURvok6wEr316E24skRvok6wSjfWozfhyhK9iTpWujHRxhK9iTpWujHRxhK9iTrBKN20\nbAmlpVBcHNh2jQkES/Qm6gSjRy9ivXoTvizRm6iiGpwePVid3oQvS/Qmqhw8CAkJ0KxZ4Nu2K29M\nuLJEb6JKMMo2lax0Y8KVJXoTVYJVtgHr0ZvwZYneRBXr0ZtoZIneRJVgJ3rr0ZtwZIneRBUr3Zho\nZIneRBUr3ZhoZIneRBUr3ZhoZIneRJVgl26sR2/Ckd+JXkRiRWSpiPzXXc4UkW9EZKOIvCUiCf6H\naUxgWI/eRKNA9Oh/BazxWH4EmKaq3YF9wI0BOIYxAZGXB2lpwWk7NRX27IGKiuC0b4yv/Er0IpIB\nXAA87y4LMBKY7u7yCnCxP8cwJpByc6F9++C0nZAArVpBQUFw2jfGV/726B8F7gIq+zApQIGqlrnL\n2UCnml4oIpNEZJGILMrLy/MzDGPqpwq7dwcv0QOkpzvHMCac+JzoReRCIFdVF/vyelV9VlUHq+rg\ntGB9lzbGw8GDEBvrjB0fLO3bO98ajAkncX68dhhwkYiMAxKB1sBjQLKIxLm9+gxgh/9hGuO/YJZt\nKlmiN+HI5x69qt6jqhmq2hWYCMxW1auAOcBl7m7XAjP8jtKYAAh22QasdGPCUzCuo78buENENuLU\n7F8IwjGMabDcXCcRB5P16E048qd0U0VV5wJz3eebgdMC0a4xgdRYpZvly4N7DGMayu6MNVGjMRJ9\nerr16E34sURvosbu3Y1TurEavQk3luhN1LCrbky0skRvooaVbky0skRvokZjXF7ZujUUFzsPY8KF\nJXoTNRrj8koRK9+Y8GOJ3kSFsjLYvz94Y9F7svKNCTeW6E1UyMtzknxsbPCPZVfemHATkBumjAl3\ndZ6IfV3qb6C2fX6ix6yy0o0JN9ajN1Fh167g1+crHXcc5OQ0zrGM8YYlehMVsrOhc+fGOVZGBuyw\nMVtNGLHSjYkK2dlOAvZGmcawt6wNRzSBco2hAqFVzGGSYwtJiCmr9/UZGTBrlp8BGxNAluhNVMjO\nhsGDj15XXFrOsu0FrM67iDXFmawv7sLO0jQKypJIjiukmZQQKxUIyqGK5hSUJdE85ggZCbvp3mw7\nPRK3M2BdLqd0aUtSYnxVuxkZsH17I/+CxtTBEr2JCtu3w4QJ8H1+ER+tyuGrDXtY+v0+uqcncVJJ\nRwa1WMtP2n1CRkIu7eL2EyfHzvCtCgcqWvL9kePYcOR4NhQfz9NzN7Fyx366t2/F2SemMabvcWRk\ntCY724sTvMY0ElE99qqBxjZ48GBdtGhRqMMwTdTeQyX07w89rlhFYYt8xvQ7jhG7buL0VqtoE3vI\nv8Z/ohSXlrN8ewGfr83l41U5UCEsuP9s1mwtpkfHFoH5JYypgYgsVtXB9e5nid40RarKku8L+NfC\nbXy+Zjfr/zKad+buY8ygdsTFxnh3SaU3ql1eqaqs3nmAswY1p+NPvmVQv3iuHtKFc3unExNjvXwT\nWN4meruFA8k4AAATkUlEQVTqxjQpqsqcdbn8+JkF3P7WMvp2bM2HvziHGI1l3OBUJ8kHkYjQr1Mb\n+p2YwKMXDuWyUzJ4cvZGzp32Bf9etJ2SsmNLQsYEm9XoTZOgqszM2s0TszdQUlbB5HO6c0H/DsTF\nxrBmjXNppTRih7pzZ8jdFctVozpx0Ukd+XpTPk/P3cTUWev55YhuTDzteOKD/EfHmEqW6E3EW7xt\nLw99uIbDpRX8enSPY8okDbm0ssE8S0AeZRzPK29EhGHdUxnWPZXl2wv468x1PP/VFu48rycX9u9g\nJR0TdJboTcTauucQj3yylmXbC7jzvJ5MOLkTsTUkzaAm+lpkZMD69ceuP6lzMq/eeDrzN+7hkU/W\n8uy8Tdx/YV9Oy2yE0dZM1LJEbyLO4ZJyHv1sPW8v2s7PzjqBaVcMJDG+9tHKGvOu2EqdO8Ps2bVv\nH9Y9lRmTh/HfFTn8+s2lnJrZjt+O601668TGC9JEDZ+LhCLSWUTmiEiWiKwWkV+569uJyCwR2eD+\nbBu4cE20m79xD2MenUfO/mJm3n42k8/pXmeSB6eEEooefX03TYkIPzqpI5/deTYZbZsz9tF5/OOL\nTXbC1gScP2eDyoA7VbUPMASYLCJ9gN8An6tqD+Bzd9kYv+wvKuWu6cv5338v5w8X9eHxK08mLamZ\nV68NVekmO9u7fVskxPG/Y3rx7i+HsXBzPuMe/5JFW/cGN0ATVXxO9Kqao6pL3OeFwBqgEzAeeMXd\n7RXgYn+DNNFLVfloZQ7nTvuC5vGxzLzjbEb2atgwlNu2wfHHBynAWqSnw4EDcKgB92NlprbkxetO\n5c5zT+SXry3h3vdXUlhcGrwgTdQIyPVdItIVOBn4BkhX1cpBWncBNf6rFJFJIrJIRBbl5eUFIgzT\nxOzaX8ykVxczddZ6nr56EA+M70erZg07rVRRAVu2wAknBClIT69L1SMmBrp1g40bG9aEiHB+/w7M\nuv1sysqV86bNY1aWzWJi/ON3oheRVsA7wK9V9YDnNnVuu63x1ltVfVZVB6vq4LS0NH/DME1IRYXy\n2jfbGPf4l/Tu0JoPbzuTU7r4dlVKTo4zYXerVgEO0gsnnljzlTfeaNMinimXDmDq5QP500drmPza\nEnILbcZx4xu/rroRkXicJP+aqr7rrt4tIh1UNUdEOgA2147x2qa8g9zz7kpKyip446Yh9Dwuyb/2\nNjk9ayBwwx54qUcP2LDBvzaGdkvh41+dxeOfb+D8R7/kN+f34rJTMpDGvPvLRDx/rroR4AVgjapO\n9dj0AXCt+/xaYIbv4ZloUVpewVNzNnLZ019zfr/jeOcXZ/id5KFaom9k/vToPSXGx3LX2F7888bT\nePnrrfz0xW/ZvrfI/4ZN1PCndDMMuAYYKSLL3Mc4YApwrohsAEa7y8bUavn2An70xFd8u2Uv/7n1\nTK4fllnjjU++CHWi97dH76lvxzbMmDyMM7qlMv6p+bw8fwvlFaEflNCEP59LN6r6FVDbv8ZRvrZr\nokdRSRlTZ67n/WU7ufeC3owf2DHgJYm1a+GyywLapNd69AhMj95TXGwMvxjRjfP6pnPPOyv5z4oc\nHrm0P93b+//txzRdNqqSCYkvN+Qx5tF57Dl4hE9/fRYXn9wpKHXnNWugd++AN+uV9HQ4cgT27eOo\nK3ICoVtaK96cNISLB3bk8n8s5MnZGygttxutTM1sCATTqAqKSvi//65h4eZ8HpzQj3N6tg/ascrK\nYPNmp4QSCiI/lG9OC0L7MTHCNUO7MrJ3Or99dyUfrpzPXy4bQL9ObYJwNBPJrEdvGoWqMmPZDs6d\nNo+kxDg+vX14UJM8OPX5jh2hefOgHqZmbu+9R8IbrH/56qAeqlNyc16+/lRuOiuT6176likfr6W4\ntDyoxzSRxXr0Jui25R/i3vdXkVd4hGevOYWTj2+c4Y+ysqBPn0Y5VK16dljH2p29jl5Zy9DG/hAR\nLhmUwVk90vjDf1Zz/mNfMuWS/px+QkpA2jeRzRK9CZrS8gqenbeZ57/czM1nd+OGMzMDN9lG9Vp3\nDQlz2TI4KfZBeP2+wBzTBycdv5wXv7ih0Y6XltSMp34yiE9X7+JXby7j3D7p3DW2J0mJ8Y0Wgwk/\nVroxQbF42z4ufNy5ZPKDW87k52d3a/QZlZYuhZO7Lm3UY1Y3sMsylm49udGPO6bvcXx6+3BKyys4\nd+o8ZizbQTjMD21Cw3r0JqB2HyjmkY/X8tXKFdzX8XkubPYl0q6RE4zb2186/3umnbOscY9dTde0\nrRw80oq8A6mktd7jWyM+lnraNHeGUVi8bR+//2AVry38ngfG96V3h9a+xWEilvXoTUAUl5bz1JyN\njH10HultEpnd82Z+lPylb/O0BuBSxLwDqRw43JrMtC0+txEIInByl6Us2TooZDGc0qUtMyafyfiT\nO3LNC9/w+xmr2F9ko2JGE0v0xi+qyierdnHutC9Yvr2A9ycP4+6xvWgVezikcS3YMJQh3RcSExP6\ncsWQ7gtZsGFoSGOIjRGuOr2LMypmhTJq6lxe/GoLR8rs6pxoYKUb47NvNufzl0/XUVhcxsMTBnBm\nj1TfG6ut9+5jr/7rDWdwRo+vfY8ngM448Wue+PTWwDfsTUmn2j5tWybw0IT+XDO0C498vJaXvt7C\n/5zXkx8N6GiTlDdhluhNg63M3s9fZq5jy56D3D76RMYPrHlS7lCav34Y9138f6EOA4ChPRZw9d//\nRXlFDLExddy96s0ftQDdWdvruNa8dP1pLNiUz5SP1/Dcl5v5n/N6cvaJaTYyZhNkid54bUV2AX+f\ns4ml2/dxy8geXDF4MAlx4Vf9O1jckqVbT+aME8OjR5+alE+X1G0s2jyY07t/G+pwjjK0WwrvTx7G\nRyt38aeP1jB11npuHdmD0b3bW8JvQizRmzqpKvM35vP0W/9gy5GO3Jj6PtOO/5Tmm4/A5mo7e3NF\nSBBuFqpubtYITj3hO1olNmAevyA7r/9MPl0xJuwSPYC8EcMFwPnthZkHhvDoZ4/wt5nruHVkD8b2\nOy7svq2ZhrNEb2p0pKycj1fu4oWvtnC4tJybk2dzUfI8EmLKAneQQE4E4tHWJyueYMyATwPXdgCM\nGfAp90//I/dfUq2cFKj3oKF/QGs4bowoY9ssYMyVZzJnXS5PzdnEnz5aw0+HduGKUzuT3CIhMLGa\nRmeJ3hzl+/wiXvt2G9MXZdOrQxK3jOzOub3TiXlzdqhD80p5RQzvfHcpc383ItShHOXs3l+wfteJ\nbM/PoHNKdqjDqZOIMLJXOiN7pbMiu4CX529l+J/ncMGAjlwzpAt9Otp1+JHGEr2hqKSMWVm7eXfJ\nDlbu2M8lJ3fi3zcP5YRZSbAc5+GNAF8544sv155Feuvd9OwY4IHg/ZQQV8rFp7zP2wsv584Lptb/\ngmDw9nPw2G/AT5SpVwwkt7CY17/5np+98h3JLRK49JQMxg/sSGqrZkEK1gSSJfooVVJWwVcb85ix\nbCez1+ZySpe2TDh8N//I/JrEAyUwK9QR+ubZ2ZO4dvgroQ6jRtee9Qo/f/Ef3DFuqm83koVQ+6RE\nfj36RG4b2YMFm/N5Z3E2j362ntMz23HBgA6M7JlOmxY2nk64skQfRfYeKmHuulw+X5vLl+vz6JGe\nxMUDO3L/hX1IadUMXp8b6hD9smNvRz5efj5/v/6XoQ6lRmf1+pL42FJmrjyPMQNmhjocn8TECMO6\npzKseyoHj5Tx6apdfLhiF/e9v5qBnZMZ0zed0X3S6dAmFGNDm9pIOAx0NHjwYF20aFGow2hyikrK\nWLKtgIWb8/l60x427D7IGd1TGNUrnRG90miflHj0CxqxxBIMP3/hGZJbFPDIlb8JdSi1emvB5fz1\no//h2z+eFnG9+rpO8haVlPHFujxmZu1mzrpcUlomMKx7Kmd0S2XoCSnW2w8SEVmsqoPr3c8SfdNQ\nUaFs21vEqh37WbVjP99t3cvaXYX07tCa0zPbMeSEFE7LbEdifGztjURwol+wYQgTpr3H6kf6kpK0\nN9Th1KqiQjjjD19z3fCXuXn0P0Idju/qSPrlFUrWzgPM37SH+Rv3sGTbPjq3a8HJxyczsHMyAzu3\npXv7VnbZZgB4m+itdBNhVJW8g0fYnHeIzXmH2JR3kFU79pO18wCtm8fTr1Nr+nZsw53n9WTQ8W1p\nnlBHYm8idu7rwMQn3uTp638R1kkeICZGeenn13P2g18wsMsyhvT4JtQhBVxsjNA/ow39M9pw89nd\nOFJWzpqcQpZ9v48Fm/J5eu4m8gqP0D09iZ7prTgxPYke6Un0TE8ivXUzu1ErCIKW6EVkLPAYEAs8\nr6pTgnWspqS0vII9B4+Qs7+YnIJicvYfZtf+YnL2F7N9XxFb8g4RHxdDZmpLTkhtSbf2rbhlZHf6\ndmxDu5bRd53zki0n8+PH/83kc59iwqnvhzocr/TutJaXJl3PRVM/4LFrfsXEoW9GXhmnAZrFxbo9\n+eSqdfuLSlmfW8j63YWs31XI52tyWb+7kEMlZWS0bUHnts3p3K4Fndu2oFPb5qQlNSO1VTPSkprR\nMiHW/hg0UFBKNyISC6wHzgWyge+AK1U1q6b9I7V0o6qUVSil5RWUlimlFRVVzw+XlnOopIyiI+7P\nkjIOHSmv+llYXEZBUQl7i0rYV1TKvkMl7Csq4XBJOW1bJtCxTSId2jTnuDaJdGiTSIfk5nRKbk63\ntJb+37gSwSUaVdhVcBzz1w/jrYVX8MXas3nsml9x5Rlvhjq0Bvtm42lMeuFZkhILuW74y4zsO5uu\nqVvDYsTNBgngHc4Hj5SxfW8R2fsOs31vEdv3FZFTUEzewSPkFR4ht7AYQUhLaka7lgm0bh5P68Q4\n92c8SVXP42iREEdifAyJ8bEkxsVWPW/m/mweH9vok+EEWkhr9CIyFPiDqo5xl+8BUNWHa9rf10T/\n/a5SzhhzCFA8fw1V8PytnG3V9qn6D1XrtWp/dX9K1doKddY7P394LuI+EGJEEIEYEWLE+QobK0JM\nTAyxlcvuutgYIS42hvjKn7ExxLnb4dhEXNvHVNP6evfN/aLa+poTv9YQR53717A+EG0AlFXEse9Q\nW/IOpJEQV8LgExYxYfB7XDn0DVq3KKzxNZGgrDyW9xZNYPo3l/H1hjPIP5hCWlIeKUn5NI8/TFxs\nmfOIKSM2phyRwP17FQLUVqcLG/EbidO5KimroKSsgrIKpayigrJydR4ey+UVSrkqFRVKhTrLFYr7\n03lo1b9hQfD8CTHuk5hq60Fq/H09V3lul8r/yrH7IfDXP8UxcVyST+9GqBP9ZcBYVf2Zu3wNcLqq\n3uKxzyRgkrvYE1jn4+FSAR+n7gmqcI0Lwjc2i6thLK6GaYpxdVHVtPp2CtnJWFV9FnjW33ZEZJE3\nf9EaW7jGBeEbm8XVMBZXw0RzXMEqUO0AOnssZ7jrjDHGNLJgJfrvgB4ikikiCcBE4IMgHcsYY0wd\nglK6UdUyEbkF+BTn8soXVXV1MI5FAMo/QRKucUH4xmZxNYzF1TBRG1dY3BlrjDEmeCL7IlJjjDH1\nskRvjDFNXJNK9CJyp4ioiKSGOhYAEfk/EVkhIstEZKaIdAx1TAAi8hcRWevG9p6IJNf/quATkR+L\nyGoRqRCRkF8GJyJjRWSdiGwUkbAZElNEXhSRXBFZFepYKolIZxGZIyJZ7mf4q1DHBCAiiSLyrYgs\nd+N6INQxeRKRWBFZKiL/DeZxmkyiF5HOwHnA96GOxcNfVHWAqg4E/gvcH+qAXLOAfqo6AGeointC\nHE+lVcAlwLxQB+IO4/EUcD7QB7hSRPqENqoqLwNjQx1ENWXAnaraBxgCTA6T9+sIMFJVTwIGAmNF\nZEiIY/L0K2BNsA/SZBI9MA24CwJ1X7f/VPWAx2JLwiQ2VZ2pqpWzfC/Euc8h5FR1jar6eod0oJ0G\nbFTVzapaArwJjA9xTACo6jwgrIbpVNUcVV3iPi/ESV6dQhsVqOOguxjvPsLi36GIZAAXAM8H+1hN\nItGLyHhgh6p6O7tpoxGRh0RkO3AV4dOj93QD8HGogwhDnYDtHsvZhEHiigQi0hU4GQiLMZjd8sgy\nIBeYpaphERfwKE7ntCLYB4qY8ehF5DPguBo2/Q74LU7ZptHVFZeqzlDV3wG/cwd2uwX4fTjE5e7z\nO5yv3K81RkzexmUil4i0At4Bfl3tG23IqGo5MNA9F/WeiPRT1ZCe3xCRC4FcVV0sIiOCfbyISfSq\nOrqm9SLSH8gElrtjVGcAS0TkNFXdFaq4avAa8BGNlOjri0tErgMuBEZpI95M0YD3K9RsGI8GEpF4\nnCT/mqq+G+p4qlPVAhGZg3N+I9QnsocBF4nIOCARaC0i/1LVq4NxsIgv3ajqSlVtr6pdVbUrzlfs\nQY2R5OsjIj08FscDa0MViyd3Upi7gItUtSjU8YQpG8ajAcTpZb0ArFHVqaGOp5KIpFVeVSYizXHm\nyAj5v0NVvUdVM9ycNRGYHawkD00g0Ye5KSKySkRW4JSWwuKSM+BJIAmY5V76+UyoAwIQkQkikg0M\nBT4UkU9DFYt7srpyGI81wNtBHMajQUTkDWAB0FNEskXkxlDHhNNDvQYY6f4/tcztrYZaB2CO+2/w\nO5wafVAvZQxHNgSCMcY0cdajN8aYJs4SvTHGNHGW6I0xpomzRG+MMU2cJXpjjGniLNEbY0wTZ4ne\nGGOauP8Hexmb8RNt2TsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f469f147b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_model.load_state_dict(best_mean_model)\n",
    "var_model.load_state_dict(best_var_model)\n",
    "mean_model.eval()\n",
    "var_model.eval()\n",
    "val_batch = next(iter(dataloader_val))\n",
    "X, Y = map(lambda x: torch.autograd.Variable(x.cuda()), val_batch)\n",
    "Y_mean_pred = mean_model(X)\n",
    "Y_var_pred = var_model(X)\n",
    "e = (Y_mean_pred - Y).cpu().data.numpy().flatten()\n",
    "ts = np.linspace(-4, 4, 400)\n",
    "handle_normal, = plt.plot(ts, 70 * norm.pdf(ts), alpha=1.0, label='$\\mathcal{N}(0, 1)$', linewidth=1.0)\n",
    "handle_normal2, = plt.plot(ts, 70 * norm.pdf(ts, loc=0, scale=1 / 5.0), alpha=1.0, color='blue', label='$\\mathcal{N}(0, 0.2^2)$', linewidth=1.0)\n",
    "error_handle = mpatches.Patch(color='orange', label='$µ(x) - y$')\n",
    "out = plt.hist(e, bins=np.linspace(-4, 4, 100), color='orange')\n",
    "plt.title('Error distribution on validation set')\n",
    "plt.legend(handles=[handle_normal, handle_normal2, error_handle])\n",
    "#plt.savefig('error_distribution.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float_formatter = lambda x: \"%.4f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " 1.00000e-03 *\n",
       "   1.4194\n",
       "  -8.6644\n",
       " [torch.cuda.FloatTensor of size 2 (GPU 0)],\n",
       " array([-0.1361, 0.1044, 0.0300, 0.5658, 0.3770]),\n",
       " array([-0.6648, 1.6073, -1.4567, 0.9170, 0.0200]),\n",
       " array([1.1253, 1.1295, 0.8637, 0.2488, 0.4508]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch = next(iter(dataloader_val))\n",
    "X, Y = map(lambda x: torch.autograd.Variable(x.cuda()), val_batch)\n",
    "Y_mean_pred = mean_model(X).cpu().data.numpy()\n",
    "Y_var_pred = var_model(X).cpu().data.numpy()\n",
    "mean_pred = Y_mean_pred * training_σ.values[-5:] + training_μ.values[-5:]\n",
    "std_pred = Y_var_pred * training_σ.values[-5:]\n",
    "y_true = Y.cpu().data.numpy() * training_σ.values[-5:] + training_µ.values[-5:]\n",
    "X[0, 6:8], mean_pred[0], y_true[0], std_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('oracle-3-units-256-hidden-mean.pkl', 'wb') as f:\n",
    "#    pickle.dump(mean_model.state_dict(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
